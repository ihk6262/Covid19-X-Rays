{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "meaningful-weekend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.5.1.48)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.3.4)\n",
      "Requirement already satisfied: imutils in /usr/local/lib/python3.8/dist-packages (0.5.4)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.8/dist-packages (1.0.0)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.4.1)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.8/dist-packages (from jupyter) (5.0.2)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from jupyter) (5.5.0)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.8/dist-packages (from jupyter) (6.2.0)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.8/dist-packages (from jupyter) (6.2.0)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from jupyter) (7.6.3)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from jupyter) (6.0.7)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (8.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.15.6)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (54.1.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2018.1.18)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter) (6.1.12)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter) (5.0.5)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter) (7.21.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (3.0.17)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (2.8.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.18.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter) (0.8.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/dist-packages (from traitlets>=4.1.0->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter) (5.1.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter) (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter) (1.0.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/lib/python3/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter) (2.6.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter) (4.7.1)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter) (20.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter) (1.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter) (22.0.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter) (0.9.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter) (2.11.3)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter) (0.9.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook->jupyter) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib/python3/dist-packages (from jinja2->notebook->jupyter) (1.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter) (0.4.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter) (0.5.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter) (3.3.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter) (1.4.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: async-generator in /usr/local/lib/python3.8/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.8/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->jupyter) (20.9)\n",
      "Requirement already satisfied: qtpy in /usr/local/lib/python3.8/dist-packages (from qtconsole->jupyter) (1.9.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.6.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "!pip3 install opencv-python matplotlib imutils jupyter sklearn tensorflow\n",
    "!apt-get install libgl1-mesa-glx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "invisible-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import save_model, load_model, Model\n",
    "from tensorflow.keras.applications import ResNet50V2, VGG16\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization, AveragePooling2D\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infinite-doubt",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## data preprocessing\n",
    "imagePath = \"./all/train\"\n",
    "imagePaths = list(paths.list_images(imagePath))\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "centered-subsection",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (200, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7fb199b38d01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minteger_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#정수로 바꿈. 라벨이 1,2,3, 처럼 숫자로 변경됨.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteger_encoded\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 라벨이 0,1,2, 에서 [1,0,0], [0,1,0] 인식하게 좋게 변경됨\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0;34m\"y should be a 1d array, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         \"got an array of shape {} instead.\".format(shape))\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (200, 3) instead."
     ]
    }
   ],
   "source": [
    "data = np.array(data) / 255.0\n",
    "labels = np.array(labels)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels) #정수로 바꿈. 라벨이 1,2,3, 처럼 숫자로 변경됨.\n",
    "labels = to_categorical(integer_encoded) # 라벨이 0,1,2, 에서 [1,0,0], [0,1,0] 인식하게 좋게 변경됨\n",
    "\n",
    "#data 를 160:40 으로 분할함.\n",
    "#train data : x_train(256*256*3 행렬), y_train(라벨)\n",
    "#test data : y_val(256*256*3 행렬), y_val(라벨)\n",
    "\n",
    "(x_train, x_val, y_train, y_val) = train_test_split(data, labels, test_size=0.20, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-bottle",
   "metadata": {},
   "source": [
    "이미지 특성 모델은 보통 다음과 같은 구조를 지닌다. \n",
    "\n",
    "합성곱 신경망 (그림의 특성을 추출) - Average2DPoolling 및 평탄화 (Flatten) - Dense layer 를 이용해서 분류\n",
    "        (베이스 모델)                                                        (헤드모델)\n",
    "        \n",
    "저희 데이터는 겨우 160개 -> 재대로 훈련을 하기에는 부족하다. \n",
    "그래서 이미 다른 좋은 데이터로 훈련시켜놓은 합성곱 신경망을 가져와서 쓸 것이다. (inceptionV3) -> google net\n",
    "그리고 우리의 데이터는 이미 훈련된 basemodel 을 건드리지 않고, headmodel 만 훈련을 시킬 것이다. \n",
    "\n",
    "이것을 전이학습 (transfer learning) 이라고 합니다.\n",
    "원래 inceptionV3 도 Dense layer 부분이 있음. 단 이 부분은 원래 데이터 분류인 1000개 분류를 합니다. \n",
    "but 우리는 3개(폐렴, 정상, Covid) -> headmodel 부분을 재구성 해야합니다. \n",
    "\n",
    "현재모델 : 합성곱 신경망 (inception V3) - Average2DPoolling 및 평탄화 (Flatten) - 128 -> 128 -> 3 구조의 Dense layer\n",
    "\n",
    "이런 전이학습의 경우에는 학습률을 평소보다 낮춰서 진행합니다.\n",
    "(평소에는 learning_rate =0.001 정도라면, 전이학습은 0.00001 로 진행해야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "future-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "adam_s = Adam(learning_rate=0.00001) # 학습율 조정\n",
    "\n",
    "baseModel = InceptionV3(input_shape=(256, 256, 3),include_top=False, weights='imagenet')\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False # 베이스 모델은 훈련시키지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "catholic-albert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 127, 127, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 127, 127, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 127, 127, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 125, 125, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 125, 125, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 125, 125, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 125, 125, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 125, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 125, 125, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 62, 62, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 62, 62, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 62, 62, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 60, 60, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 60, 60, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 60, 60, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 29, 29, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 29, 29, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 29, 29, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 29, 29, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 29, 29, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 29, 29, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 29, 29, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 29, 29, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 29, 29, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 29, 29, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 29, 29, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 29, 29, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 29, 29, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 29, 29, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 29, 29, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 29, 29, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 29, 29, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 29, 29, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 29, 29, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 29, 29, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 29, 29, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 29, 29, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 29, 29, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 29, 29, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 29, 29, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 29, 29, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 29, 29, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 29, 29, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 29, 29, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 29, 29, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 29, 29, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 29, 29, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 29, 29, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 29, 29, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 29, 29, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 29, 29, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 29, 29, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 29, 29, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 29, 29, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 29, 29, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 29, 29, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 29, 29, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 29, 29, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 29, 29, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 29, 29, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 29, 29, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 29, 29, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 29, 29, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 29, 29, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 29, 29, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 29, 29, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 29, 29, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 29, 29, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 29, 29, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 29, 29, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 29, 29, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 29, 29, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 29, 29, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 29, 29, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 29, 29, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 14, 14, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 14, 14, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 14, 14, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 14, 14, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 14, 14, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 14, 14, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 14, 14, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 14, 14, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 14, 14, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 14, 14, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 14, 14, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 14, 14, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 14, 14, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 14, 14, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 14, 14, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 14, 14, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 14, 14, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 14, 14, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 14, 14, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 14, 14, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 14, 14, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 14, 14, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 14, 14, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 14, 14, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 14, 14, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 14, 14, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 14, 14, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 14, 14, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 14, 14, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 14, 14, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 14, 14, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 14, 14, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 14, 14, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 14, 14, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 14, 14, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 14, 14, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 14, 14, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 14, 14, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 14, 14, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 14, 14, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 14, 14, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 14, 14, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 14, 14, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 14, 14, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 14, 14, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 14, 14, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 14, 14, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 14, 14, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 14, 14, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 14, 14, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 14, 14, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 14, 14, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 14, 14, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 14, 14, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 14, 14, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 14, 14, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 14, 14, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 14, 14, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 14, 14, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 14, 14, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 14, 14, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 14, 14, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 14, 14, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 14, 14, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 14, 14, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 14, 14, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 14, 14, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 14, 14, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 14, 14, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 14, 14, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 14, 14, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 14, 14, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 14, 14, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 14, 14, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 14, 14, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 14, 14, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 14, 14, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 14, 14, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 14, 14, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 14, 14, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 14, 14, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 14, 14, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 14, 14, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 14, 14, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 14, 14, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 14, 14, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 14, 14, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 14, 14, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 14, 14, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 14, 14, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 6, 6, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 6, 6, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 6, 6, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 6, 6, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 6, 6, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 6, 6, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 6, 6, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 6, 6, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 6, 6, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 6, 6, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 6, 6, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 6, 6, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 6, 6, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 6, 6, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 6, 6, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 6, 6, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 6, 6, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 6, 6, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 6, 6, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 6, 6, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 6, 6, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 6, 6, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 6, 6, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 6, 6, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 6, 6, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 6, 6, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 6, 6, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 6, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 6, 6, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 6, 6, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 6, 6, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 6, 6, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 6, 6, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 6, 6, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 6, 6, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 6, 6, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 6, 6, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 6, 6, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 6, 6, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 6, 6, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 6, 6, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 6, 6, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 6, 6, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 6, 6, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 6, 6, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 6, 6, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 6, 6, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 6, 6, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 6, 6, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 6, 6, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 6, 6, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 6, 6, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 6, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 6, 6, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 1, 1, 2048)   0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          262272      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            387         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,081,955\n",
      "Trainable params: 279,171\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(4,4))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation='relu')(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(128, activation='relu')(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(3, activation='softmax')(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "#tensorflow 는 모델 구조를 만들고 컴파일을 해줘야 한다.\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam_s, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adopted-beijing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - 15s 507ms/step - loss: 1.5711 - accuracy: 0.3313 - val_loss: 1.3628 - val_accuracy: 0.3000\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 9s 428ms/step - loss: 1.6089 - accuracy: 0.3045 - val_loss: 1.2877 - val_accuracy: 0.3250\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 8s 423ms/step - loss: 1.3570 - accuracy: 0.3710 - val_loss: 1.2366 - val_accuracy: 0.2750\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 8s 423ms/step - loss: 1.4002 - accuracy: 0.3592 - val_loss: 1.1887 - val_accuracy: 0.3250\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 8s 412ms/step - loss: 1.3643 - accuracy: 0.3139 - val_loss: 1.1532 - val_accuracy: 0.3000\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 1.2721 - accuracy: 0.3470 - val_loss: 1.1248 - val_accuracy: 0.3500\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 1.3256 - accuracy: 0.3417 - val_loss: 1.1002 - val_accuracy: 0.3250\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 8s 428ms/step - loss: 1.2225 - accuracy: 0.4454 - val_loss: 1.0777 - val_accuracy: 0.3500\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 8s 395ms/step - loss: 1.1817 - accuracy: 0.4155 - val_loss: 1.0562 - val_accuracy: 0.3500\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 1.2529 - accuracy: 0.3354 - val_loss: 1.0379 - val_accuracy: 0.3750\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 8s 415ms/step - loss: 1.0922 - accuracy: 0.4269 - val_loss: 1.0200 - val_accuracy: 0.4000\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 8s 413ms/step - loss: 1.1445 - accuracy: 0.4205 - val_loss: 1.0021 - val_accuracy: 0.4000\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 8s 415ms/step - loss: 1.1202 - accuracy: 0.3742 - val_loss: 0.9862 - val_accuracy: 0.4500\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 8s 408ms/step - loss: 1.0673 - accuracy: 0.4717 - val_loss: 0.9749 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 9s 437ms/step - loss: 0.9852 - accuracy: 0.4849 - val_loss: 0.9636 - val_accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 8s 416ms/step - loss: 0.9269 - accuracy: 0.5329 - val_loss: 0.9494 - val_accuracy: 0.6500\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 0.9956 - accuracy: 0.5232 - val_loss: 0.9355 - val_accuracy: 0.6500\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 8s 413ms/step - loss: 1.0936 - accuracy: 0.4152 - val_loss: 0.9246 - val_accuracy: 0.7250\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 8s 430ms/step - loss: 0.9725 - accuracy: 0.5306 - val_loss: 0.9130 - val_accuracy: 0.7750\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 8s 411ms/step - loss: 0.9310 - accuracy: 0.5652 - val_loss: 0.9021 - val_accuracy: 0.7750\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 8s 414ms/step - loss: 0.9785 - accuracy: 0.4697 - val_loss: 0.8865 - val_accuracy: 0.7750\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 8s 419ms/step - loss: 0.9001 - accuracy: 0.5834 - val_loss: 0.8765 - val_accuracy: 0.7750\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 8s 417ms/step - loss: 0.9413 - accuracy: 0.5861 - val_loss: 0.8673 - val_accuracy: 0.7750\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 8s 417ms/step - loss: 1.0256 - accuracy: 0.4291 - val_loss: 0.8562 - val_accuracy: 0.8000\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 8s 405ms/step - loss: 0.8908 - accuracy: 0.5838 - val_loss: 0.8486 - val_accuracy: 0.8000\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 8s 422ms/step - loss: 1.0527 - accuracy: 0.4298 - val_loss: 0.8415 - val_accuracy: 0.8000\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 8s 412ms/step - loss: 0.9711 - accuracy: 0.4836 - val_loss: 0.8337 - val_accuracy: 0.8000\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 8s 423ms/step - loss: 0.8752 - accuracy: 0.5692 - val_loss: 0.8246 - val_accuracy: 0.8000\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 8s 419ms/step - loss: 0.9276 - accuracy: 0.5677 - val_loss: 0.8181 - val_accuracy: 0.8000\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 8s 427ms/step - loss: 0.9110 - accuracy: 0.5697 - val_loss: 0.8106 - val_accuracy: 0.7750\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 8s 415ms/step - loss: 0.8182 - accuracy: 0.6698 - val_loss: 0.8029 - val_accuracy: 0.8000\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 8s 409ms/step - loss: 0.8412 - accuracy: 0.6440 - val_loss: 0.7950 - val_accuracy: 0.7750\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 8s 415ms/step - loss: 0.9160 - accuracy: 0.5968 - val_loss: 0.7863 - val_accuracy: 0.8000\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 8s 413ms/step - loss: 0.9128 - accuracy: 0.5197 - val_loss: 0.7774 - val_accuracy: 0.8000\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 8s 425ms/step - loss: 0.8238 - accuracy: 0.7233 - val_loss: 0.7679 - val_accuracy: 0.8000\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 8s 415ms/step - loss: 0.8852 - accuracy: 0.5931 - val_loss: 0.7603 - val_accuracy: 0.8000\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 8s 419ms/step - loss: 0.8784 - accuracy: 0.6855 - val_loss: 0.7519 - val_accuracy: 0.7750\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 8s 400ms/step - loss: 0.9224 - accuracy: 0.5489 - val_loss: 0.7423 - val_accuracy: 0.7750\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 8s 415ms/step - loss: 0.8631 - accuracy: 0.5811 - val_loss: 0.7342 - val_accuracy: 0.7500\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 8s 409ms/step - loss: 0.9004 - accuracy: 0.5354 - val_loss: 0.7276 - val_accuracy: 0.7750\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 8s 417ms/step - loss: 0.7231 - accuracy: 0.6888 - val_loss: 0.7218 - val_accuracy: 0.8000\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 8s 410ms/step - loss: 0.8300 - accuracy: 0.6270 - val_loss: 0.7153 - val_accuracy: 0.8000\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 8s 408ms/step - loss: 0.8253 - accuracy: 0.6619 - val_loss: 0.7103 - val_accuracy: 0.8000\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 0.7616 - accuracy: 0.6417 - val_loss: 0.7043 - val_accuracy: 0.8000\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 8s 408ms/step - loss: 0.8240 - accuracy: 0.5958 - val_loss: 0.7004 - val_accuracy: 0.8000\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 8s 419ms/step - loss: 0.8137 - accuracy: 0.6689 - val_loss: 0.6915 - val_accuracy: 0.8000\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 8s 410ms/step - loss: 0.7537 - accuracy: 0.6539 - val_loss: 0.6858 - val_accuracy: 0.8000\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 8s 410ms/step - loss: 0.9229 - accuracy: 0.5358 - val_loss: 0.6780 - val_accuracy: 0.8000\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 8s 416ms/step - loss: 0.6908 - accuracy: 0.6991 - val_loss: 0.6682 - val_accuracy: 0.8250\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 8s 417ms/step - loss: 0.7585 - accuracy: 0.7065 - val_loss: 0.6624 - val_accuracy: 0.8250\n"
     ]
    }
   ],
   "source": [
    "# training AI model\n",
    "H = model.fit(x_train, y_train, epochs=50, validation_data=(x_val, y_val), batch_size=8) # 어떤데이터가 train 이고 test 인지가 중요함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "brilliant-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: head-base-covid/1/assets\n"
     ]
    }
   ],
   "source": [
    "## save AI model\n",
    "save_model(model, \"head-base-covid/1\") #1은 버전 최종은 꼭 숫자로 이루어져야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"inceptionv3_base.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "whole-action",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0 13  1]\n",
      " [ 4  2  8]]\n",
      " \n",
      "accuracy: 0.8250\n",
      "sensitivity: 1.0000\n",
      "specificity: 0.8571\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization (Optional)\n",
    "P = model.predict(x_val, batch_size=8)\n",
    "P = np.argmax(P, axis=1)\n",
    "# print(classification_report(y_val.argmax(axis=1), P, target_names=label_encoder.classes_))\n",
    " \n",
    "epochs = 50\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend(loc=\"right\")\n",
    "plt.savefig(\"./s-class-plot-2.png\")\n",
    " \n",
    "cm = confusion_matrix(y_val.argmax(axis=1), P)\n",
    "total = sum(sum(cm))\n",
    "acc = (cm[0, 0] + cm[1, 1] + cm[2, 2]) / total\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1] + cm[0, 2])\n",
    "specificity = (cm[1, 1] + cm[1, 2] + cm[2, 1] + cm[2, 2]) / (cm[1, 0] + cm[1, 1] + cm[1, 2] + cm[2, 0] + cm[2, 1] + cm[2, 2])\n",
    " \n",
    "print(cm)\n",
    "print(\" \")\n",
    "print(\"accuracy: {:.4f}\".format(acc))\n",
    "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "print(\"specificity: {:.4f}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dominant-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "frequent-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing\n",
    "imagePathTest = \"./all/test\"\n",
    "imagePathsTest = list(paths.list_images(imagePathTest))\n",
    " \n",
    "dataTest = []\n",
    "labelsTest = []\n",
    " \n",
    "for imagePathTest in imagePathsTest:\n",
    "    labelTest = imagePathTest.split(os.path.sep)[-2]\n",
    "    imageTest = cv2.imread(imagePathTest)\n",
    "    imageTest = cv2.cvtColor(imageTest, cv2.COLOR_BGR2RGB)\n",
    "    imageTest = cv2.resize(imageTest, (256, 256))\n",
    "    dataTest.append(imageTest)\n",
    "    labelsTest.append(labelTest)\n",
    "     \n",
    "dataTest = np.array(dataTest) / 255.0\n",
    "labelsTest = np.array(labelsTest)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labelsTest)\n",
    "labelsTest = to_categorical(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "previous-billy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# Choose a random image and make JSON\n",
    "sam = random.randint(0, len(imagePathsTest)-1)\n",
    "print(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rational-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data = dataTest[sam]\n",
    "sample_test_labels = labelsTest[sam]\n",
    "#sam 에 맞는 그림 선택 -> 256, 256, 3\n",
    "sample_test_data = np.expand_dims(sample_test_data, axis=0)\n",
    "# 256, 256, 3 -> 1, 256, 256, 3\n",
    "data = json.dumps({\"signature_name\": \"serving_default\",\n",
    "                   \"instances\": sample_test_data.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "governing-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"please.json\", \"w\") as text_file:\n",
    "    text_file.write(\"%s\" % data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "indirect-kansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"predictions\": [[0.950093925, 0.0168375634, 0.033068575]\r\n",
      "    ]\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!curl 35.230.4.132:8501/v1/models/covid/versions/1:predict -X POST -d@please.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
